{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first try to train and optimize some ML algorithms to predict the survival of individuals, using all available and meaningful data, \n",
    "\n",
    "### and then, following the data analysis, we search for the best algorithm only for predicting the survival of males, following the schema:\n",
    "- if female:\n",
    "    - if all family died:\n",
    "        - predict die\n",
    "    - else predict survive\n",
    "- if male:\n",
    "    - if all family survives:\n",
    "        - predict survive\n",
    "    - else predict survival using ML on data: IsYoung, PClass, and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LogExpFunctions ──── v0.2.3\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GLFW_jll ─────────── v3.3.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ArrayInterface ───── v3.1.9\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLBase ───────────── v0.8.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Zygote ───────────── v0.6.10\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JuliaInterpreter ─── v0.8.14\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArrays ─────── v1.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRules ───────── v0.7.61\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m HTTP ─────────────── v0.9.7\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenSpecFun_jll ──── v0.5.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StructTypes ──────── v1.7.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatsBase ────────── v0.33.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Grisu ────────────── v1.0.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJModels ────────── v0.14.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalArrays ── v0.9.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OffsetArrays ─────── v1.7.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJTuning ────────── v0.6.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Colors ───────────── v0.12.8\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRulesCore ───── v0.9.40\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJScientificTypes ─ v0.4.5\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NNlib ────────────── v0.7.19\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distributions ────── v0.24.18\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FileIO ───────────── v1.8.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ColorSchemes ─────── v3.12.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Project.toml`\n",
      " \u001b[90m [f0e99cf1] \u001b[39m\u001b[92m+ MLBase v0.8.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.6/Manifest.toml`\n",
      " \u001b[90m [4fba245c] \u001b[39m\u001b[93m↑ ArrayInterface v3.1.7 ⇒ v3.1.9\u001b[39m\n",
      " \u001b[90m [324d7699] \u001b[39m\u001b[93m↑ CategoricalArrays v0.9.5 ⇒ v0.9.6\u001b[39m\n",
      " \u001b[90m [082447d4] \u001b[39m\u001b[93m↑ ChainRules v0.7.60 ⇒ v0.7.61\u001b[39m\n",
      " \u001b[90m [d360d2e6] \u001b[39m\u001b[93m↑ ChainRulesCore v0.9.37 ⇒ v0.9.40\u001b[39m\n",
      " \u001b[90m [35d6a980] \u001b[39m\u001b[93m↑ ColorSchemes v3.12.0 ⇒ v3.12.1\u001b[39m\n",
      " \u001b[90m [5ae59095] \u001b[39m\u001b[93m↑ Colors v0.12.7 ⇒ v0.12.8\u001b[39m\n",
      " \u001b[90m [8f4d0f93] \u001b[39m\u001b[93m↑ Conda v1.5.1 ⇒ v1.5.2\u001b[39m\n",
      " \u001b[90m [31c24e10] \u001b[39m\u001b[93m↑ Distributions v0.24.15 ⇒ v0.24.18\u001b[39m\n",
      " \u001b[90m [5789e2e9] \u001b[39m\u001b[93m↑ FileIO v1.6.5 ⇒ v1.8.1\u001b[39m\n",
      " \u001b[90m [28b8d3ca] \u001b[39m\u001b[93m↑ GR v0.57.3 ⇒ v0.57.4\u001b[39m\n",
      " \u001b[90m [42e2da0e] \u001b[39m\u001b[93m↑ Grisu v1.0.0 ⇒ v1.0.1\u001b[39m\n",
      " \u001b[90m [cd3eb016] \u001b[39m\u001b[93m↑ HTTP v0.9.5 ⇒ v0.9.7\u001b[39m\n",
      " \u001b[90m [692b3bcd] \u001b[39m\u001b[93m↑ JLLWrappers v1.2.0 ⇒ v1.3.0\u001b[39m\n",
      " \u001b[90m [aa1ae85d] \u001b[39m\u001b[93m↑ JuliaInterpreter v0.8.13 ⇒ v0.8.14\u001b[39m\n",
      " \u001b[90m [2ab3a3ac] \u001b[39m\u001b[93m↑ LogExpFunctions v0.2.1 ⇒ v0.2.3\u001b[39m\n",
      " \u001b[90m [f0e99cf1] \u001b[39m\u001b[92m+ MLBase v0.8.0\u001b[39m\n",
      " \u001b[90m [d491faf4] \u001b[39m\u001b[93m↑ MLJModels v0.14.2 ⇒ v0.14.4\u001b[39m\n",
      " \u001b[90m [2e2323e0] \u001b[39m\u001b[93m↑ MLJScientificTypes v0.4.4 ⇒ v0.4.5\u001b[39m\n",
      " \u001b[90m [03970b2e] \u001b[39m\u001b[93m↑ MLJTuning v0.6.4 ⇒ v0.6.5\u001b[39m\n",
      " \u001b[90m [872c559c] \u001b[39m\u001b[93m↑ NNlib v0.7.18 ⇒ v0.7.19\u001b[39m\n",
      " \u001b[90m [6fe1bfb0] \u001b[39m\u001b[93m↑ OffsetArrays v1.6.2 ⇒ v1.7.0\u001b[39m\n",
      " \u001b[90m [189a3867] \u001b[39m\u001b[95m↓ Reexport v1.0.0 ⇒ v0.2.0\u001b[39m\n",
      " \u001b[90m [90137ffa] \u001b[39m\u001b[93m↑ StaticArrays v1.1.0 ⇒ v1.1.2\u001b[39m\n",
      " \u001b[90m [2913bbd2] \u001b[39m\u001b[93m↑ StatsBase v0.33.5 ⇒ v0.33.6\u001b[39m\n",
      " \u001b[90m [856f2bd8] \u001b[39m\u001b[93m↑ StructTypes v1.6.0 ⇒ v1.7.2\u001b[39m\n",
      " \u001b[90m [e88e6eb3] \u001b[39m\u001b[93m↑ Zygote v0.6.9 ⇒ v0.6.10\u001b[39m\n",
      " \u001b[90m [0656b61e] \u001b[39m\u001b[93m↑ GLFW_jll v3.3.3+0 ⇒ v3.3.4+0\u001b[39m\n",
      " \u001b[90m [efe28fd5] \u001b[39m\u001b[93m↑ OpenSpecFun_jll v0.5.3+4 ⇒ v0.5.4+0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGrisu\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStructTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLogExpFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRulesCore\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOffsetArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mShowoff\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSpecFun_jll\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mCategoricalArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGLFW_jll\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mSpecialFunctions\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJScientificTypes\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mHTTP\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mFileIO\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mStatsFuns\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMultivariateStats\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mLatinHypercubeSampling\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mLightGBM\n",
      "\u001b[33m  ? \u001b[39mMLBase\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJOpenML\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mWebSockets\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mJuliaInterpreter\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDistributions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLossFunctions\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJMultivariateStatsInterface\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mColors\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJBase\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mWidgets\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mFlameGraphs\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJTuning\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mScikitLearn\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mMLJModels\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mMLJ\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mChainRules\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mGeometryBasics\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mDiffResults\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mContour\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mFiniteDiff\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mColorSchemes\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mForwardDiff\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mClustering\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mKernelDensity\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mNearestNeighborModels\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mPlotUtils\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mPlots\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mOptim\u001b[39m\n",
      "\u001b[33m  ? \u001b[39m\u001b[90mZygote\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mAtom\n",
      "\u001b[33m  ? \u001b[39mStatsPlots\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCUDA\u001b[39m\n",
      "\u001b[33m  ? \u001b[39mFlux\n",
      "\u001b[33m  ? \u001b[39mEvoTrees\n",
      "\u001b[33m  ? \u001b[39mMLJFlux\n",
      "21 dependencies successfully precompiled in 43 seconds (222 already precompiled)\n",
      "\u001b[33m39\u001b[39m dependencies failed but may be precompilable after restarting julia\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add([\"CSV\", \"DataFrames\", \"Statistics\", \"MLJ\", \"MLJFlux\", \"Flux\", \"MLJLIBSVMInterface\", \"NearestNeighborModels\", \"MLBase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MLBase [f0e99cf1-93fa-52ec-9ecc-5026115318e0]\n",
      "└ @ Base loading.jl:1317\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule StatsBase with build ID 38744959248947 is missing from the cache.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis may mean StatsBase [2913bbd2-ae8a-5f71-8c99-4fb6c76f3a91] does not support precompilation but is imported by a module that does.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Base loading.jl:1008\u001b[39m\n",
      "┌ Info: Skipping precompilation since __precompile__(false). Importing MLBase [f0e99cf1-93fa-52ec-9ecc-5026115318e0].\n",
      "└ @ Base loading.jl:1025\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, Statistics, MLJ, MLJFlux, Flux, MLJLIBSVMInterface, NearestNeighborModels, MLBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.File(\"data/train.csv\") |> DataFrame\n",
    "X_pred = CSV.File(\"data/test.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a pipeline for pre-processing the data\n",
    "The columns we will use are:\n",
    "* Sex\n",
    "* IsYoung / CategoricalAge\n",
    "* Pclass\n",
    "* Embarked\n",
    "* FamilySurvived\n",
    "\n",
    "We will also have to change the scientific type of our data for it to work with the Julia ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "port_to_numerical (generic function with 2 methods)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function encodes the port name\n",
    "function port_to_numerical(port)\n",
    "    if ismissing(port) || port == \"S\"\n",
    "        return 0 \n",
    "    elseif port == \"C\"\n",
    "        return 2\n",
    "    else\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_family_dict (generic function with 1 method)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex to extract first name\n",
    "family_name_regex = r\"^([\\w\\-]+)\"\n",
    "\n",
    "# Function returns a dictionary containing family names as keys, \n",
    "# and an array with the \"Survived\" label for all family members as value \n",
    "function get_family_dict(data)\n",
    "    family_dict = Dict()\n",
    "    \n",
    "    # extract string\n",
    "    for value in eachrow(data)\n",
    "        name = match(family_name_regex, value.Name).match\n",
    "        if haskey(family_dict, name)\n",
    "            # push survived value to set matching the name \n",
    "            push!(get(family_dict, name, nothing), value.Survived)\n",
    "        else\n",
    "            # if dict does not contain this family, create a new set containing the \"Survived\" value of this person\n",
    "            family_dict[name] = [value.Survived]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return family_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_survived (generic function with 1 method)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function returns 0 if all family died\n",
    "# - 1 if the person is travelling alone or family has mixed survival\n",
    "# - 2 if all family survived\n",
    "function family_survived(example, family_dict)\n",
    "    name = match(family_name_regex, example.Name).match\n",
    "    \n",
    "    if haskey(family_dict, name) && length(get(family_dict, name, nothing)) > 1\n",
    "        value = get(family_dict, name, nothing)\n",
    "        if mean(value) == 1\n",
    "            # all family survived\n",
    "            return 2\n",
    "        elseif mean(value) == 0\n",
    "            # all family died\n",
    "            return 0\n",
    "        end\n",
    "        # mixed survival\n",
    "        return 1\n",
    "    else\n",
    "        # person is travelling alone\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre_process (generic function with 3 methods)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for pre-processing the data\n",
    "# If given training data, only the \"data\" parameter has to be speciffied.\n",
    "# For data to be predicted, the family dictionary must also be passed.\n",
    "# @return family_dict only for training data.\n",
    "function pre_process(data; train=true, family_dict=missing)\n",
    "    # Sex to numerical\n",
    "    data.Sex = map(x -> x == \"male\" ? 0 : 1, data.Sex)\n",
    "    \n",
    "    # IsYoung / Age\n",
    "    # TODO\n",
    "    data.Age = map(x -> !ismissing(x) && x < 14 ? 1 : 0, data.Age)\n",
    "    rename!(data, :Age => :IsYoung)\n",
    "    \n",
    "    # Embarked to numerical\n",
    "    data.Embarked = map(x -> port_to_numerical(x), data.Embarked)\n",
    "    \n",
    "    # FamilySurvived\n",
    "    if train\n",
    "        family_dict = get_family_dict(data)\n",
    "    end\n",
    "    data.FamilySurvived = map(x -> family_survived(x, family_dict), eachrow(data))\n",
    "        \n",
    "    # drop cols\n",
    "    select!(data, Not([:PassengerId, :Name, :SibSp, :Parch, :Fare, :Ticket, :Cabin]))\n",
    "    \n",
    "    # scitype\n",
    "    coerce!(data, Count => Continuous)\n",
    "    if train\n",
    "        coerce!(data, :Survived => OrderedFactor)\n",
    "        return family_dict\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict = pre_process(data)\n",
    "pre_process(X_pred, train=false, family_dict=family_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data now is in the right format. The next step is to break it into examples and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(data, ==(:Survived), x->true, rng=123);\n",
    "# shuffle data with a seed to mentain a certain consistency between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find models that can be fitted to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype), T} where T<:Tuple}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " ⋮\n",
       " (name = RandomForestClassifier, package_name = BetaML, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_to_file (generic function with 1 method)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function write_to_file(data, path::String)\n",
    "    fw = open(path, \"w\")\n",
    "    write(fw, \"PassengerId,Survived\\n\")\n",
    "    close(fw)\n",
    "    fw = open(path, \"a\")\n",
    "    index = 892\n",
    "    for value in data\n",
    "        write(fw, \"$index,$value\\n\")\n",
    "        index += 1\n",
    "    end\n",
    "    close(fw)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks time :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the best results, we must first normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standardizer(\n",
       "    features = Symbol[],\n",
       "    ignore = false,\n",
       "    ordered_factor = false,\n",
       "    count = false)\u001b[34m @372\u001b[39m"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand = Standardizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJFlux ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n",
      "┌ Warning: `acceleration isa CUDALibs` but no CUDA device (GPU) currently live. \n",
      "└ @ MLJFlux /home/ahautelman/.julia/packages/MLJFlux/AeMUx/src/classifier.jl:39\n"
     ]
    }
   ],
   "source": [
    "Model = @load NeuralNetworkClassifier\n",
    "# we'll use mini-batch for training the MLP for faster convergence\n",
    "# also change the number of hidden neurons from the default 0 to 10 \n",
    "#     to allow the network to learn the, possibly, more complex relations between features. \n",
    "model = Model(builder=MLJFlux.Short(n_hidden=10, σ=Flux.elu, dropout=0.2),\n",
    "    epochs=200, batch_size=100,\n",
    "    acceleration=CUDALibs());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = @pipeline stand model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(MLJBase.NumericRange)(Float64, :(neural_network_classifier.builder.dropout), ... )"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some ranges for the hyper-parameters that we want to optimize.\n",
    "r = range(pipe, :(neural_network_classifier.lambda), lower=0.0, upper=10.0)\n",
    "r2 = range(pipe, :(neural_network_classifier.alpha), lower=0.0, upper=4.0)\n",
    "r3 = range(pipe, :(neural_network_classifier.builder.dropout), lower=0, upper=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TunedModel(model=pipe,\n",
    "                   ranges = [r, r2, r3],\n",
    "                   resampling=Holdout(fraction_train=0.8, shuffle=true),\n",
    "                   measures=cross_entropy,\n",
    "                   repeats=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @865\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Attempting to evaluate 1000 models.\n",
      "└ @ MLJTuning /home/ahautelman/.julia/packages/MLJTuning/9sSuR/src/tuned_models.jl:564\n",
      "\u001b[33mEvaluating over 1000 metamodels: 100%[=========================] Time: 0:35:50\u001b[39m\n",
      "┌ Warning: `acceleration isa CUDALibs` but no CUDA device (GPU) currently live. \n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @865\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @800\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @456\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(model, X, y)\n",
    "MLJ.fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14606741573033707"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = predict(mach, X[test, :]);\n",
    "misclassification_rate(mode.(ŷ), y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, mode.(predict(mach, X_pred)));\n",
    "write_to_file(prediction, \"data/nn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.78708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"NN.jlso\", mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLIBSVMInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(\n",
       "    kernel = LIBSVM.Kernel.RadialBasis,\n",
       "    gamma = 0.0,\n",
       "    weights = nothing,\n",
       "    cost = 1.0,\n",
       "    cachesize = 200.0,\n",
       "    degree = 3,\n",
       "    coef0 = 0.0,\n",
       "    tolerance = 0.001,\n",
       "    shrinking = true,\n",
       "    probability = false)\u001b[34m @564\u001b[39m"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = @pipeline stand model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{Pipeline423,…} @698\u001b[39m trained 0 times; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @191\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @996\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Pipeline423,…} @698\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Training \u001b[34mMachine{Standardizer,…} @476\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Training \u001b[34mMachine{SVC,…} @949\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{Pipeline423,…} @698\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @191\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @996\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13108614232209737"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = predict(mach, X[test, :])\n",
    "misclassification_rate(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even better score for the SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, predict(mach, X_pred))\n",
    "write_to_file(prediction, \"data/svc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.78468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"SVC.jlso\", mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(\n",
       "    max_depth = -1,\n",
       "    min_samples_leaf = 1,\n",
       "    min_samples_split = 2,\n",
       "    min_purity_increase = 0.0,\n",
       "    n_subfeatures = -1,\n",
       "    n_trees = 10,\n",
       "    sampling_fraction = 0.7,\n",
       "    pdf_smoothing = 0.0)\u001b[34m @446\u001b[39m"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = @load RandomForestClassifier pkg=\"DecisionTree\"\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = range(model, :min_samples_leaf, lower=1, upper=20)\n",
    "r3 = range(model, :min_samples_split, lower=1, upper=40)\n",
    "r4 = range(model, :n_subfeatures, lower=0, upper=5)\n",
    "r5 = range(model, :n_trees, lower=2, upper=15)\n",
    "r6 = range(model, :sampling_fraction, lower=0.5, upper=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticTunedModel(\n",
       "    model = RandomForestClassifier(\n",
       "            max_depth = -1,\n",
       "            min_samples_leaf = 1,\n",
       "            min_samples_split = 2,\n",
       "            min_purity_increase = 0.0,\n",
       "            n_subfeatures = -1,\n",
       "            n_trees = 10,\n",
       "            sampling_fraction = 0.7,\n",
       "            pdf_smoothing = 0.0),\n",
       "    tuning = Grid(\n",
       "            goal = nothing,\n",
       "            resolution = 10,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    resampling = Holdout(\n",
       "            fraction_train = 0.8,\n",
       "            shuffle = true,\n",
       "            rng = Random._GLOBAL_RNG()),\n",
       "    measure = LogLoss(\n",
       "            tol = 2.220446049250313e-16),\n",
       "    weights = nothing,\n",
       "    operation = MLJModelInterface.predict,\n",
       "    range = MLJBase.NumericRange{T, MLJBase.Bounded, Symbol} where T[\u001b[34mNumericRange{Int64,…} @286\u001b[39m, \u001b[34mNumericRange{Int64,…} @121\u001b[39m, \u001b[34mNumericRange{Int64,…} @141\u001b[39m, \u001b[34mNumericRange{Int64,…} @883\u001b[39m, \u001b[34mNumericRange{Float64,…} @909\u001b[39m],\n",
       "    selection_heuristic = MLJTuning.NaiveSelection(nothing),\n",
       "    train_best = true,\n",
       "    repeats = 5,\n",
       "    n = 100000,\n",
       "    acceleration = CPUProcesses{Nothing}(nothing),\n",
       "    acceleration_resampling = CPU1{Nothing}(nothing),\n",
       "    check_measure = true,\n",
       "    cache = true)\u001b[34m @531\u001b[39m"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TunedModel(model=model,\n",
    "                  ranges=[r2, r3, r4, r5, r6],\n",
    "                  resampling=Holdout(fraction_train=0.8, shuffle=true),\n",
    "                  measures=cross_entropy,\n",
    "                  repeats=5,\n",
    "                  n=100000,\n",
    "                  acceleration=CPUProcesses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(model, X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @842\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Attempting to evaluate 100000 models.\n",
      "└ @ MLJTuning /home/ahautelman/.julia/packages/MLJTuning/9sSuR/src/tuned_models.jl:564\n",
      "\u001b[33mEvaluating over 60000 metamodels: 100%[=========================] Time: 0:07:32\u001b[39m\n",
      "┌ Info: Only 60000 (of 100000) models evaluated.\n",
      "│ Model supply exhausted. \n",
      "└ @ MLJTuning /home/ahautelman/.julia/packages/MLJTuning/9sSuR/src/tuned_models.jl:505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @842\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @112\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @544\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18352059925093633"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = mode.(predict(mach, X[test, :]))\n",
    "misclassification_rate(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, mode.(predict(mach, X_pred)))\n",
    "write_to_file(prediction, \"data/random_forest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.77751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"random_forest.jlso\", mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN clasiffier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import NearestNeighborModels ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = Uniform())\u001b[34m @085\u001b[39m"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load KNNClassifier pkg=\"NearestNeighborModels\"\n",
    "model = KNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline462(\n",
       "    standardizer = Standardizer(\n",
       "            features = Symbol[],\n",
       "            ignore = false,\n",
       "            ordered_factor = false,\n",
       "            count = false),\n",
       "    knn_classifier = KNNClassifier(\n",
       "            K = 5,\n",
       "            algorithm = :kdtree,\n",
       "            metric = Euclidean(0.0),\n",
       "            leafsize = 10,\n",
       "            reorder = true,\n",
       "            weights = Uniform()))\u001b[34m @366\u001b[39m"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = @pipeline stand model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(MLJBase.NominalRange)(Int64, :(knn_classifier.K), ... )"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(pipe, :(knn_classifier.K), values=2:40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TunedModel(model=pipe,\n",
    "                   ranges=r,\n",
    "                   resampling=Holdout(fraction_train=0.8, shuffle=true),\n",
    "                   measures=cross_entropy,\n",
    "                   repeats=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @013\u001b[39m trained 0 times; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @727\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @406\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @013\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Attempting to evaluate 39 models.\n",
      "└ @ MLJTuning /home/ahautelman/.julia/packages/MLJTuning/9sSuR/src/tuned_models.jl:564\n",
      "\u001b[33mEvaluating over 39 metamodels: 100%[=========================] Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @013\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @727\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @406\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1647940074906367"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = mode.(predict(mach, X[test, :]))\n",
    "misclassification_rate(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, mode.(predict(mach, X_pred)))\n",
    "write_to_file(prediction, \"data/knn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.78947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"knn.jlso\", mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light gbm ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: use other approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we have seen, the algorithms are all consistent and have good results.\n",
    "But we got an accuracy increase of only 2% compared to the naive 'all women survive' prediction.\n",
    "\n",
    "To change the tactics a bit, we will go by this next schema in the steps to come:\n",
    "- if female:\n",
    "    - if all family died:\n",
    "        - predict die\n",
    "    - else predict survive\n",
    "- if male:\n",
    "    - if all family survives:\n",
    "        - predict survive\n",
    "    - else predict survival using ML algorithm on data: IsYoung, PClass, and Embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Survived</th><th>Pclass</th><th>IsYoung</th><th>Embarked</th></tr><tr><th></th><th>Cat…</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>553 rows × 4 columns</p><tr><th>1</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>0.0</td><td>3.0</td><td>0.0</td><td>1.0</td></tr><tr><th>4</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>0.0</td><td>3.0</td><td>1.0</td><td>0.0</td></tr><tr><th>6</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>7</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>0.0</td><td>3.0</td><td>1.0</td><td>1.0</td></tr><tr><th>9</th><td>1.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>1.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>0.0</td><td>3.0</td><td>0.0</td><td>2.0</td></tr><tr><th>14</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>17</th><td>0.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>19</th><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>1.0</td><td>3.0</td><td>0.0</td><td>2.0</td></tr><tr><th>21</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>22</th><td>0.0</td><td>3.0</td><td>0.0</td><td>2.0</td></tr><tr><th>23</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>0.0</td><td>3.0</td><td>0.0</td><td>1.0</td></tr><tr><th>25</th><td>0.0</td><td>3.0</td><td>0.0</td><td>2.0</td></tr><tr><th>26</th><td>0.0</td><td>3.0</td><td>1.0</td><td>0.0</td></tr><tr><th>27</th><td>0.0</td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td></tr><tr><th>29</th><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>0.0</td><td>3.0</td><td>0.0</td><td>2.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Survived & Pclass & IsYoung & Embarked\\\\\n",
       "\t\\hline\n",
       "\t& Cat… & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 0.0 & 3.0 & 0.0 & 1.0 \\\\\n",
       "\t4 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 0.0 & 3.0 & 1.0 & 0.0 \\\\\n",
       "\t6 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t7 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t8 & 0.0 & 3.0 & 1.0 & 1.0 \\\\\n",
       "\t9 & 1.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t10 & 0.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t11 & 1.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t12 & 1.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t13 & 0.0 & 3.0 & 0.0 & 2.0 \\\\\n",
       "\t14 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t15 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t16 & 0.0 & 1.0 & 0.0 & 2.0 \\\\\n",
       "\t17 & 0.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t18 & 0.0 & 1.0 & 0.0 & 2.0 \\\\\n",
       "\t19 & 0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t20 & 1.0 & 3.0 & 0.0 & 2.0 \\\\\n",
       "\t21 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t22 & 0.0 & 3.0 & 0.0 & 2.0 \\\\\n",
       "\t23 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t24 & 0.0 & 3.0 & 0.0 & 1.0 \\\\\n",
       "\t25 & 0.0 & 3.0 & 0.0 & 2.0 \\\\\n",
       "\t26 & 0.0 & 3.0 & 1.0 & 0.0 \\\\\n",
       "\t27 & 0.0 & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t28 & 0.0 & 1.0 & 0.0 & 2.0 \\\\\n",
       "\t29 & 1.0 & 1.0 & 0.0 & 0.0 \\\\\n",
       "\t30 & 0.0 & 3.0 & 0.0 & 2.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m553×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Survived \u001b[0m\u001b[1m Pclass  \u001b[0m\u001b[1m IsYoung \u001b[0m\u001b[1m Embarked \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Cat…     \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼──────────────────────────────────────\n",
       "   1 │ 0.0           3.0      0.0       0.0\n",
       "   2 │ 0.0           3.0      0.0       0.0\n",
       "   3 │ 0.0           3.0      0.0       1.0\n",
       "   4 │ 0.0           1.0      0.0       0.0\n",
       "   5 │ 0.0           3.0      1.0       0.0\n",
       "   6 │ 0.0           3.0      0.0       0.0\n",
       "   7 │ 0.0           3.0      0.0       0.0\n",
       "   8 │ 0.0           3.0      1.0       1.0\n",
       "   9 │ 1.0           2.0      0.0       0.0\n",
       "  10 │ 0.0           2.0      0.0       0.0\n",
       "  11 │ 1.0           2.0      0.0       0.0\n",
       "  ⋮  │    ⋮         ⋮        ⋮        ⋮\n",
       " 544 │ 0.0           3.0      0.0       0.0\n",
       " 545 │ 0.0           3.0      0.0       0.0\n",
       " 546 │ 0.0           3.0      0.0       0.0\n",
       " 547 │ 0.0           3.0      0.0       0.0\n",
       " 548 │ 0.0           3.0      0.0       0.0\n",
       " 549 │ 0.0           2.0      0.0       0.0\n",
       " 550 │ 0.0           3.0      0.0       0.0\n",
       " 551 │ 0.0           2.0      0.0       0.0\n",
       " 552 │ 1.0           1.0      0.0       2.0\n",
       " 553 │ 0.0           3.0      0.0       1.0\n",
       "\u001b[36m                            532 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_males = deepcopy(data)\n",
    "data_males = filter(x -> x.Sex == 0 && x.FamilySurvived != 2, data_males)\n",
    "select!(data_males, Not([:Sex, :FamilySurvived]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(data_males, ==(:Survived), x->true, rng=123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNClassifier(\n",
       "    K = 5,\n",
       "    algorithm = :kdtree,\n",
       "    metric = Euclidean(0.0),\n",
       "    leafsize = 10,\n",
       "    reorder = true,\n",
       "    weights = Uniform())\u001b[34m @284\u001b[39m"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline497(\n",
       "    standardizer = Standardizer(\n",
       "            features = Symbol[],\n",
       "            ignore = false,\n",
       "            ordered_factor = false,\n",
       "            count = false),\n",
       "    knn_classifier = KNNClassifier(\n",
       "            K = 5,\n",
       "            algorithm = :kdtree,\n",
       "            metric = Euclidean(0.0),\n",
       "            leafsize = 10,\n",
       "            reorder = true,\n",
       "            weights = Uniform()))\u001b[34m @107\u001b[39m"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = @pipeline stand model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = range(pipe, :(knn_classifier.K), values=2:40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TunedModel(model=pipe,\n",
    "#                    ranges=r,\n",
    "#                    resampling=Holdout(fraction_train=0.8, shuffle=true),\n",
    "#                    measures=cross_entropy,\n",
    "#                    repeats=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier,…} @977\u001b[39m trained 0 times; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @468\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @073\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{KNNClassifier,…} @977\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{KNNClassifier,…} @977\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @468\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @073\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = mode.(predict(mach, X[test, :]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2289156626506024"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_rate(prediction, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching confusmat(::Int64, ::CategoricalArrays.CategoricalVector{Float64, UInt32, Float64, CategoricalArrays.CategoricalValue{Float64, UInt32}, Union{}}, ::CategoricalArrays.CategoricalVector{Float64, UInt32, Float64, CategoricalArrays.CategoricalValue{Float64, UInt32}, Union{}})\n\u001b[0mClosest candidates are:\n\u001b[0m  confusmat(::Integer, \u001b[91m::AbstractVector{T} where T<:Integer\u001b[39m, \u001b[91m::AbstractVector{T} where T<:Integer\u001b[39m) at /home/ahautelman/.julia/packages/MLBase/85ImQ/src/perfeval.jl:10",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching confusmat(::Int64, ::CategoricalArrays.CategoricalVector{Float64, UInt32, Float64, CategoricalArrays.CategoricalValue{Float64, UInt32}, Union{}}, ::CategoricalArrays.CategoricalVector{Float64, UInt32, Float64, CategoricalArrays.CategoricalValue{Float64, UInt32}, Union{}})\n\u001b[0mClosest candidates are:\n\u001b[0m  confusmat(::Integer, \u001b[91m::AbstractVector{T} where T<:Integer\u001b[39m, \u001b[91m::AbstractVector{T} where T<:Integer\u001b[39m) at /home/ahautelman/.julia/packages/MLBase/85ImQ/src/perfeval.jl:10",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[334]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "MLBase.confusmat(2, y[test], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type NamedTuple has no field best_model",
     "output_type": "error",
     "traceback": [
      "type NamedTuple has no field best_model",
      "",
      "Stacktrace:",
      " [1] getproperty(x::NamedTuple{(), Tuple{}}, f::Symbol)",
      "   @ Base ./Base.jl:33",
      " [2] top-level scope",
      "   @ In[324]:1",
      " [3] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# report(mach).best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(x -> x == 1, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(data, family_dict, mach)\n",
    "    ŷ = []\n",
    "    for value in eachrow(data)\n",
    "        push!(ŷ, predict_example(value, family_dict, mach))\n",
    "    end\n",
    "    return ŷ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_example(example, family_dict, mach)\n",
    "    regex = r\"^([\\w\\-]+)\"\n",
    "    name = match(regex, example.Name).match\n",
    "    if example.Sex == \"female\"\n",
    "        if haskey(family_dict, name)\n",
    "            value = get(family_dict, name, missing)\n",
    "            if size(value)[1] > 1 && mean(value) == 0\n",
    "                return 0\n",
    "            end\n",
    "        end\n",
    "        return 1    \n",
    "    else\n",
    "        if haskey(family_dict, name)\n",
    "            value = get(family_dict, name, missing)\n",
    "            if size(value)[1] > 1 && mean(value) == 1\n",
    "                return 1\n",
    "            end\n",
    "        end\n",
    "        return predict(mach, example)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: create pipeline for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
