{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first try to train and optimize some ML algorithms to predict the survival of individuals, using all available and meaningful data, and then, following the data analysis, we search for the best algorithm only for predicting the survival of males, following the schema:\n",
    "- if female:\n",
    "    - if all family died:\n",
    "        - predict die\n",
    "    - else predict survive\n",
    "- if male:\n",
    "    - if all family survives:\n",
    "        - predict survive\n",
    "    - else predict survival using ML on data: IsYoung, PClass, and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add([\"CSV\", \"DataFrames\", \"Statistics\", \"MLJ\", \"MLJFlux\", \"Flux\", \"MLJLIBSVMInterface\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, MLJ, MLJFlux, Flux, MLJLIBSVMInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.File(\"data/train.csv\") |> DataFrame\n",
    "X_pred = CSV.File(\"data/test.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a pipeline for pre-processing the data\n",
    "The columns we will use are:\n",
    "* Sex\n",
    "* IsYoung / CategoricalAge\n",
    "* Pclass\n",
    "* Embarked\n",
    "* FamilySurvived\n",
    "\n",
    "We will also have to change the scientific type of our data for it to work with the Julia ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "port_to_numerical (generic function with 2 methods)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function encodes the port name\n",
    "function port_to_numerical(port)\n",
    "    if ismissing(port) || port == \"S\"\n",
    "        return 0 \n",
    "    elseif port == \"C\"\n",
    "        return 2\n",
    "    else\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_family_dict (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex to extract first name\n",
    "family_name_regex = r\"^([\\w\\-]+)\"\n",
    "\n",
    "# Function returns a dictionary containing family names as keys, \n",
    "# and an array with the \"Survived\" label for all family members as value \n",
    "function get_family_dict(data)\n",
    "    family_dict = Dict()\n",
    "    \n",
    "    # extract string\n",
    "    for value in eachrow(data)\n",
    "        name = match(family_name_regex, value.Name).match\n",
    "        if haskey(family_dict, name)\n",
    "            # push survived value to set matching the name \n",
    "            push!(get(family_dict, name, nothing), value.Survived)\n",
    "        else\n",
    "            # if dict does not contain this family, create a new set containing the \"Survived\" value of this person\n",
    "            family_dict[name] = [value.Survived]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return family_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_survived (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function returns 0 if all family died\n",
    "# - 1 if the person is travelling alone or family has mixed survival\n",
    "# - 2 if all family survived\n",
    "function family_survived(example, family_dict)\n",
    "    name = match(family_name_regex, example.Name).match\n",
    "    \n",
    "    if haskey(family_dict, name) && length(get(family_dict, name, nothing)) > 1\n",
    "        value = get(family_dict, name, nothing)\n",
    "        if mean(value) == 1\n",
    "            # all family survived\n",
    "            return 2\n",
    "        elseif mean(value) == 0\n",
    "            # all family died\n",
    "            return 0\n",
    "        end\n",
    "        # mixed survival\n",
    "        return 1\n",
    "    else\n",
    "        # person is travelling alone\n",
    "        return 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre_process (generic function with 3 methods)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for pre-processing the data\n",
    "# If given training data, only the \"data\" parameter has to be speciffied.\n",
    "# For data to be predicted, the family dictionary must also be passed.\n",
    "# @return family_dict only for training data.\n",
    "function pre_process(data; train=true, family_dict=missing)\n",
    "    # Sex to numerical\n",
    "    data.Sex = map(x -> x == \"male\" ? 0 : 1, data.Sex)\n",
    "    \n",
    "    # IsYoung / Age\n",
    "    # TODO\n",
    "    data.Age = map(x -> !ismissing(x) && x < 14 ? 1 : 0, data.Age)\n",
    "    rename!(data, :Age => :IsYoung)\n",
    "    \n",
    "    # Embarked to numerical\n",
    "    data.Embarked = map(x -> port_to_numerical(x), data.Embarked)\n",
    "    \n",
    "    # FamilySurvived\n",
    "    if train\n",
    "        family_dict = get_family_dict(data)\n",
    "    end\n",
    "    data.FamilySurvived = map(x -> family_survived(x, family_dict), eachrow(data))\n",
    "        \n",
    "    # drop cols\n",
    "    select!(data, Not([:PassengerId, :Name, :SibSp, :Parch, :Fare, :Ticket, :Cabin]))\n",
    "    \n",
    "    # scitype\n",
    "    coerce!(data, Count => Continuous)\n",
    "    if train\n",
    "        coerce!(data, :Survived => OrderedFactor)\n",
    "        return family_dict\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict = pre_process(data)\n",
    "pre_process(X_pred, train=false, family_dict=family_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data now is in the right format. The next step is to break it into examples and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(data, ==(:Survived), x->true, rng=123);\n",
    "# shuffle data with a seed to mentain a certain consistency between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = partition(eachindex(y), 0.7, shuffle=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find models that can be fitted to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :docstring, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :is_pure_julia, :is_wrapper, :load_path, :package_license, :package_url, :package_uuid, :prediction_type, :supports_online, :supports_weights, :input_scitype, :target_scitype, :output_scitype), T} where T<:Tuple}:\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BayesianLDA, package_name = MultivariateStats, ... )\n",
       " (name = BayesianLDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianQDA, package_name = ScikitLearn, ... )\n",
       " (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = ConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DecisionTreeClassifier, package_name = BetaML, ... )\n",
       " (name = DecisionTreeClassifier, package_name = DecisionTree, ... )\n",
       " (name = DeterministicConstantClassifier, package_name = MLJModels, ... )\n",
       " (name = DummyClassifier, package_name = ScikitLearn, ... )\n",
       " (name = EvoTreeClassifier, package_name = EvoTrees, ... )\n",
       " ⋮\n",
       " (name = RandomForestClassifier, package_name = BetaML, ... )\n",
       " (name = RandomForestClassifier, package_name = DecisionTree, ... )\n",
       " (name = RandomForestClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeCVClassifier, package_name = ScikitLearn, ... )\n",
       " (name = RidgeClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SGDClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVC, package_name = LIBSVM, ... )\n",
       " (name = SVMClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMLinearClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SVMNuClassifier, package_name = ScikitLearn, ... )\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models(matching(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write_to_file (generic function with 1 method)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function write_to_file(data, path::String)\n",
    "    fw = open(path, \"w\")\n",
    "    write(fw, \"PassengerId,Survived\\n\")\n",
    "    close(fw)\n",
    "    fw = open(path, \"a\")\n",
    "    index = 892\n",
    "    for value in data\n",
    "        write(fw, \"$index,$value\\n\")\n",
    "        index += 1\n",
    "    end\n",
    "    close(fw)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks time :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the best results, we must first normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standardizer(\n",
       "    features = Symbol[],\n",
       "    ignore = false,\n",
       "    ordered_factor = false,\n",
       "    count = false)\u001b[34m @372\u001b[39m"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand = Standardizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJFlux ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n",
      "┌ Warning: `acceleration isa CUDALibs` but no CUDA device (GPU) currently live. \n",
      "└ @ MLJFlux /home/ahautelman/.julia/packages/MLJFlux/AeMUx/src/classifier.jl:39\n"
     ]
    }
   ],
   "source": [
    "Model = @load NeuralNetworkClassifier\n",
    "# we'll use mini-batch for training the MLP for faster convergence\n",
    "# also change the number of hidden neurons from the default 0 to 10 \n",
    "#     to allow the network to learn the, possibly, more complex relations between features. \n",
    "model = Model(builder=MLJFlux.Short(n_hidden=10, σ=Flux.elu, dropout=0.2),\n",
    "    epochs=200, batch_size=100,\n",
    "    acceleration=CUDALibs());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = @pipeline stand model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(MLJBase.NumericRange)(Float64, :(neural_network_classifier.builder.dropout), ... )"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some ranges for the hyper-parameters that we want to optimize.\n",
    "r = range(pipe, :(neural_network_classifier.lambda), lower=0.0, upper=10.0)\n",
    "r2 = range(pipe, :(neural_network_classifier.alpha), lower=0.0, upper=4.0)\n",
    "r3 = range(pipe, :(neural_network_classifier.builder.dropout), lower=0, upper=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TunedModel(model=pipe,\n",
    "                   ranges = [r, r2, r3],\n",
    "                   resampling=Holdout(fraction_train=0.8, shuffle=true),\n",
    "                   measures=cross_entropy,\n",
    "                   repeats=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @865\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Attempting to evaluate 1000 models.\n",
      "└ @ MLJTuning /home/ahautelman/.julia/packages/MLJTuning/9sSuR/src/tuned_models.jl:564\n",
      "\u001b[33mEvaluating over 1000 metamodels: 100%[=========================] Time: 0:35:50\u001b[39m\n",
      "┌ Warning: `acceleration isa CUDALibs` but no CUDA device (GPU) currently live. \n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{ProbabilisticTunedModel{Grid,…},…} @865\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @800\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @456\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(model, X, y)\n",
    "MLJ.fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14606741573033707"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = predict(mach, X[test, :]);\n",
    "misclassification_rate(mode.(ŷ), y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, mode.(predict(mach, X_pred)));\n",
    "write_to_file(prediction, \"data/nn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.78708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"NN.jlso\", mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLIBSVMInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ahautelman/.julia/packages/MLJModels/zYlo3/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(\n",
       "    kernel = LIBSVM.Kernel.RadialBasis,\n",
       "    gamma = 0.0,\n",
       "    weights = nothing,\n",
       "    cost = 1.0,\n",
       "    cachesize = 200.0,\n",
       "    degree = 3,\n",
       "    coef0 = 0.0,\n",
       "    tolerance = 0.001,\n",
       "    shrinking = true,\n",
       "    probability = false)\u001b[34m @564\u001b[39m"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = @pipeline stand model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{Pipeline423,…} @698\u001b[39m trained 0 times; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @191\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @996\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = machine(pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training \u001b[34mMachine{Pipeline423,…} @698\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Training \u001b[34mMachine{Standardizer,…} @476\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n",
      "┌ Info: Training \u001b[34mMachine{SVC,…} @949\u001b[39m.\n",
      "└ @ MLJBase /home/ahautelman/.julia/packages/MLJBase/KWyqX/src/machines.jl:342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[34mMachine{Pipeline423,…} @698\u001b[39m trained 1 time; caches data\n",
       "  args: \n",
       "    1:\t\u001b[34mSource @191\u001b[39m ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\t\u001b[34mSource @996\u001b[39m ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach, rows=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13108614232209737"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = predict(mach, X[test, :])\n",
    "misclassification_rate(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even better score for the SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = convert(Array{Int64}, predict(mach, X_pred))\n",
    "write_to_file(prediction, \"data/svc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 0.78468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.save(\"SVC.jlso\", mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
